{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ğŸ” Sentence Embeddings & Similarity Explorer\n",
        "\n",
        "This notebook explores **three different embedding models** and compares how they measure semantic similarity between sentences:\n",
        "\n",
        "1. **MiniLM** (all-MiniLM-L6-v2) - Lightweight, fast, 384 dimensions\n",
        "2. **MPNet** (all-mpnet-base-v2) - Higher quality, 768 dimensions  \n",
        "3. **OpenAI** (text-embedding-3-large) - Cloud-based, 3072 dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leonardoheis/Source/repo/jargons_test/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Core imports\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize OpenAI client\n",
        "openai_client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“ Define Test Sentences\n",
        "\n",
        "Let's define a set of sentences with varying degrees of semantic similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total sentences: 8\n",
            "  [0] The cat is sleeping on the couch.\n",
            "  [1] A feline is resting on the sofa.\n",
            "  [2] The dog is playing in the garden.\n",
            "  [3] Machine learning models require training data.\n",
            "  [4] Neural networks need datasets for training.\n",
            "  [5] The weather is beautiful today.\n",
            "  [6] It's a lovely sunny day outside.\n",
            "  [7] Python is a popular programming language.\n"
          ]
        }
      ],
      "source": [
        "# Define test sentences - some are semantically similar, others are not\n",
        "sentences = [\n",
        "    \"The cat is sleeping on the couch.\",\n",
        "    \"A feline is resting on the sofa.\",\n",
        "    \"The dog is playing in the garden.\",\n",
        "    \"Machine learning models require training data.\",\n",
        "    \"Neural networks need datasets for training.\",\n",
        "    \"The weather is beautiful today.\",\n",
        "    \"It's a lovely sunny day outside.\",\n",
        "    \"Python is a popular programming language.\",\n",
        "]\n",
        "\n",
        "print(f\"Total sentences: {len(sentences)}\")\n",
        "for i, s in enumerate(sentences):\n",
        "    print(f\"  [{i}] {s}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  Model 1: all-MiniLM-L6-v2\n",
        "\n",
        "A lightweight, fast model that provides good quality embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape: (8, 384)\n",
            "Each sentence is represented by a 384-dimensional vector\n"
          ]
        }
      ],
      "source": [
        "# Load the MiniLM model\n",
        "model_minilm = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings_minilm = model_minilm.encode(sentences)\n",
        "\n",
        "print(f\"Embedding shape: {embeddings_minilm.shape}\")\n",
        "print(f\"Each sentence is represented by a {embeddings_minilm.shape[1]}-dimensional vector\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Similarity Matrix (all-MiniLM-L6-v2):\n",
            "       S0     S1     S2     S3     S4     S5     S6     S7\n",
            "S0  1.000  0.556  0.086 -0.045 -0.047 -0.098 -0.116  0.030\n",
            "S1  0.556  1.000  0.075 -0.035 -0.047 -0.016  0.006  0.032\n",
            "S2  0.086  0.075  1.000 -0.028 -0.092  0.118  0.194  0.021\n",
            "S3 -0.045 -0.035 -0.028  1.000  0.741 -0.027  0.007  0.113\n",
            "S4 -0.047 -0.047 -0.092  0.741  1.000 -0.055 -0.051  0.101\n",
            "S5 -0.098 -0.016  0.118 -0.027 -0.055  1.000  0.783  0.047\n",
            "S6 -0.116  0.006  0.194  0.007 -0.051  0.783  1.000  0.062\n",
            "S7  0.030  0.032  0.021  0.113  0.101  0.047  0.062  1.000\n"
          ]
        }
      ],
      "source": [
        "# Compute cosine similarity matrix\n",
        "similarity_matrix_minilm = cosine_similarity(embeddings_minilm)\n",
        "\n",
        "# Display as a DataFrame for better readability\n",
        "df_sim_minilm = pd.DataFrame(\n",
        "    similarity_matrix_minilm,\n",
        "    index=[f\"S{i}\" for i in range(len(sentences))],\n",
        "    columns=[f\"S{i}\" for i in range(len(sentences))]\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š Similarity Matrix (all-MiniLM-L6-v2):\")\n",
        "print(df_sim_minilm.round(3).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  Model 2: all-mpnet-base-v2\n",
        "\n",
        "A more powerful model with higher quality embeddings (but slower)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "547a94f9343f4f8f9c8632e4387b1969",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f9fde9af2e1541c68d62dbd67657a604",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fd3f951759c445188225bb0812d1c3f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ebee51e9ab1644e6a5cc1a534bc4d39c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "30e162664edc476aae3a9308e5a64d51",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3055cf7dc27b433ca0458eb814cd560e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e45a9e8231b54050a2b6429cbebeafca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b8899c275e4413682de73066c7e2052",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c88a19545b84ae2976825873eda9d85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4031f7f8a04d4a2c99841d05b18e7ffb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a86617584045a0b51cc7ef264ca85d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape: (8, 768)\n",
            "Each sentence is represented by a 768-dimensional vector\n"
          ]
        }
      ],
      "source": [
        "# Load the MPNet model\n",
        "model_mpnet = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "# Generate embeddings\n",
        "embeddings_mpnet = model_mpnet.encode(sentences)\n",
        "\n",
        "print(f\"Embedding shape: {embeddings_mpnet.shape}\")\n",
        "print(f\"Each sentence is represented by a {embeddings_mpnet.shape[1]}-dimensional vector\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Similarity Matrix (all-mpnet-base-v2):\n",
            "       S0     S1     S2     S3     S4     S5     S6     S7\n",
            "S0  1.000  0.679 -0.060 -0.002  0.028 -0.028 -0.172 -0.054\n",
            "S1  0.679  1.000  0.002  0.019  0.059  0.079 -0.023  0.002\n",
            "S2 -0.060  0.002  1.000 -0.024 -0.032  0.217  0.209  0.080\n",
            "S3 -0.002  0.019 -0.024  1.000  0.675 -0.043 -0.054  0.272\n",
            "S4  0.028  0.059 -0.032  0.675  1.000 -0.018 -0.017  0.132\n",
            "S5 -0.028  0.079  0.217 -0.043 -0.018  1.000  0.770  0.007\n",
            "S6 -0.172 -0.023  0.209 -0.054 -0.017  0.770  1.000  0.026\n",
            "S7 -0.054  0.002  0.080  0.272  0.132  0.007  0.026  1.000\n"
          ]
        }
      ],
      "source": [
        "# Compute cosine similarity matrix\n",
        "similarity_matrix_mpnet = cosine_similarity(embeddings_mpnet)\n",
        "\n",
        "# Display as a DataFrame\n",
        "df_sim_mpnet = pd.DataFrame(\n",
        "    similarity_matrix_mpnet,\n",
        "    index=[f\"S{i}\" for i in range(len(sentences))],\n",
        "    columns=[f\"S{i}\" for i in range(len(sentences))]\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š Similarity Matrix (all-mpnet-base-v2):\")\n",
        "print(df_sim_mpnet.round(3).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§  Model 3: OpenAI text-embedding-3-large\n",
        "\n",
        "OpenAI's state-of-the-art embedding model with 3072 dimensions (can be reduced)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding shape: (8, 3072)\n",
            "Each sentence is represented by a 3072-dimensional vector\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings using OpenAI\n",
        "response = openai_client.embeddings.create(\n",
        "    model=\"text-embedding-3-large\",\n",
        "    input=sentences\n",
        ")\n",
        "\n",
        "embeddings_openai = np.array([item.embedding for item in response.data])\n",
        "\n",
        "print(f\"Embedding shape: {embeddings_openai.shape}\")\n",
        "print(f\"Each sentence is represented by a {embeddings_openai.shape[1]}-dimensional vector\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Similarity Matrix (OpenAI text-embedding-3-large):\n",
            "       S0     S1     S2     S3     S4     S5     S6     S7\n",
            "S0  1.000  0.717  0.250  0.079  0.071  0.129  0.142  0.076\n",
            "S1  0.717  1.000  0.276  0.065  0.059  0.151  0.184  0.092\n",
            "S2  0.250  0.276  1.000  0.028  0.042  0.213  0.275  0.084\n",
            "S3  0.079  0.065  0.028  1.000  0.698  0.043  0.062  0.170\n",
            "S4  0.071  0.059  0.042  0.698  1.000  0.036  0.049  0.171\n",
            "S5  0.129  0.151  0.213  0.043  0.036  1.000  0.688  0.102\n",
            "S6  0.142  0.184  0.275  0.062  0.049  0.688  1.000  0.113\n",
            "S7  0.076  0.092  0.084  0.170  0.171  0.102  0.113  1.000\n"
          ]
        }
      ],
      "source": [
        "# Compute cosine similarity matrix\n",
        "similarity_matrix_openai = cosine_similarity(embeddings_openai)\n",
        "\n",
        "# Display as a DataFrame\n",
        "df_sim_openai = pd.DataFrame(\n",
        "    similarity_matrix_openai,\n",
        "    index=[f\"S{i}\" for i in range(len(sentences))],\n",
        "    columns=[f\"S{i}\" for i in range(len(sentences))]\n",
        ")\n",
        "\n",
        "print(\"\\nğŸ“Š Similarity Matrix (OpenAI text-embedding-3-large):\")\n",
        "print(df_sim_openai.round(3).to_string())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ”„ Compare Models: Side-by-Side Analysis\n",
        "\n",
        "Let's see how all three models compare for specific sentence pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”„ Model Comparison for Selected Pairs (3 Models):\n",
            "                            Sentence 1                             Sentence 2  MiniLM  MPNet  OpenAI\n",
            "     The cat is sleeping on the couch.       A feline is resting on the sofa.   0.556  0.679   0.717\n",
            "     The cat is sleeping on the couch.      The dog is playing in the garden.   0.086 -0.060   0.250\n",
            "Machine learning models require tra... Neural networks need datasets for t...   0.741  0.675   0.698\n",
            "       The weather is beautiful today.       It's a lovely sunny day outside.   0.783  0.770   0.688\n",
            "     The cat is sleeping on the couch. Python is a popular programming lan...   0.030 -0.054   0.076\n",
            "Machine learning models require tra... Python is a popular programming lan...   0.113  0.272   0.170\n"
          ]
        }
      ],
      "source": [
        "# Define interesting pairs to compare\n",
        "pairs_to_compare = [\n",
        "    (0, 1),  # Cat sleeping vs Feline resting (should be very similar)\n",
        "    (0, 2),  # Cat sleeping vs Dog playing (different but related - pets)\n",
        "    (3, 4),  # ML models vs Neural networks (semantically similar)\n",
        "    (5, 6),  # Weather beautiful vs Sunny day (semantically similar)\n",
        "    (0, 7),  # Cat sleeping vs Python programming (unrelated)\n",
        "    (3, 7),  # ML models vs Python programming (somewhat related)\n",
        "]\n",
        "\n",
        "comparison_results = []\n",
        "for i, j in pairs_to_compare:\n",
        "    comparison_results.append({\n",
        "        \"Sentence 1\": sentences[i][:35] + \"...\" if len(sentences[i]) > 35 else sentences[i],\n",
        "        \"Sentence 2\": sentences[j][:35] + \"...\" if len(sentences[j]) > 35 else sentences[j],\n",
        "        \"MiniLM\": round(similarity_matrix_minilm[i][j], 3),\n",
        "        \"MPNet\": round(similarity_matrix_mpnet[i][j], 3),\n",
        "        \"OpenAI\": round(similarity_matrix_openai[i][j], 3),\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_results)\n",
        "print(\"\\nğŸ”„ Model Comparison for Selected Pairs (3 Models):\")\n",
        "print(df_comparison.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ¯ Find Most Similar Sentences\n",
        "\n",
        "Given a query sentence, find the most similar sentences from our list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ” Query: 'Deep learning requires lots of data to work properly.'\n",
            "\n",
            "Top 3 most similar sentences (using MINILM):\n",
            "  1. [0.613] Neural networks need datasets for training.\n",
            "  2. [0.551] Machine learning models require training data.\n",
            "  3. [0.118] Python is a popular programming language.\n",
            "\n",
            "Top 3 most similar sentences (using MPNET):\n",
            "  1. [0.674] Neural networks need datasets for training.\n",
            "  2. [0.558] Machine learning models require training data.\n",
            "  3. [0.227] Python is a popular programming language.\n",
            "\n",
            "Top 3 most similar sentences (using OPENAI):\n",
            "  1. [0.667] Machine learning models require training data.\n",
            "  2. [0.658] Neural networks need datasets for training.\n",
            "  3. [0.166] Python is a popular programming language.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leonardoheis/Source/repo/jargons_test/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/leonardoheis/Source/repo/jargons_test/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/leonardoheis/Source/repo/jargons_test/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        }
      ],
      "source": [
        "def find_most_similar(query: str, corpus: list[str], model_name: str = \"minilm\", top_k: int = 3):\n",
        "    \"\"\"Find the top-k most similar sentences to the query.\"\"\"\n",
        "    \n",
        "    if model_name == \"openai\":\n",
        "        # Use OpenAI API for embeddings\n",
        "        all_texts = [query] + corpus\n",
        "        response = openai_client.embeddings.create(\n",
        "            model=\"text-embedding-3-large\",\n",
        "            input=all_texts\n",
        "        )\n",
        "        all_embeddings = np.array([item.embedding for item in response.data])\n",
        "        query_embedding = all_embeddings[0:1]\n",
        "        corpus_embeddings = all_embeddings[1:]\n",
        "    else:\n",
        "        # Use SentenceTransformer models\n",
        "        model = model_minilm if model_name == \"minilm\" else model_mpnet\n",
        "        query_embedding = model.encode([query])\n",
        "        corpus_embeddings = model.encode(corpus)\n",
        "    \n",
        "    # Compute similarities\n",
        "    similarities = cosine_similarity(query_embedding, corpus_embeddings)[0]\n",
        "    \n",
        "    # Get top-k indices\n",
        "    top_indices = np.argsort(similarities)[::-1][:top_k]\n",
        "    \n",
        "    results = []\n",
        "    for idx in top_indices:\n",
        "        results.append({\n",
        "            \"sentence\": corpus[idx],\n",
        "            \"similarity\": round(similarities[idx], 4)\n",
        "        })\n",
        "    return results\n",
        "\n",
        "# Test with a query across all models\n",
        "query = \"Deep learning requires lots of data to work properly.\"\n",
        "print(f\"\\nğŸ” Query: '{query}'\\n\")\n",
        "\n",
        "for model_name in [\"minilm\", \"mpnet\", \"openai\"]:\n",
        "    print(f\"Top 3 most similar sentences (using {model_name.upper()}):\")\n",
        "    for i, result in enumerate(find_most_similar(query, sentences, model_name), 1):\n",
        "        print(f\"  {i}. [{result['similarity']:.3f}] {result['sentence']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸŒ¡ï¸ Similarity Threshold Analysis\n",
        "\n",
        "Understand what different similarity scores mean in practice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸŒ¡ï¸ Similarity Categories (using MiniLM):\n",
            "--------------------------------------------------------------------------------\n",
            "S5-S6: 0.783 ğŸŸ¡ High (semantically similar)\n",
            "   â†’ The weather is beautiful today...\n",
            "   â†’ It's a lovely sunny day outsid...\n",
            "\n",
            "S3-S4: 0.741 ğŸŸ¡ High (semantically similar)\n",
            "   â†’ Machine learning models requir...\n",
            "   â†’ Neural networks need datasets ...\n",
            "\n",
            "S0-S1: 0.556 ğŸŸ  Moderate (somewhat related)\n",
            "   â†’ The cat is sleeping on the cou...\n",
            "   â†’ A feline is resting on the sof...\n",
            "\n",
            "S2-S6: 0.194 âš« Very Low (unrelated)\n",
            "   â†’ The dog is playing in the gard...\n",
            "   â†’ It's a lovely sunny day outsid...\n",
            "\n",
            "S2-S5: 0.118 âš« Very Low (unrelated)\n",
            "   â†’ The dog is playing in the gard...\n",
            "   â†’ The weather is beautiful today...\n",
            "\n",
            "S3-S7: 0.113 âš« Very Low (unrelated)\n",
            "   â†’ Machine learning models requir...\n",
            "   â†’ Python is a popular programmin...\n",
            "\n",
            "S4-S7: 0.101 âš« Very Low (unrelated)\n",
            "   â†’ Neural networks need datasets ...\n",
            "   â†’ Python is a popular programmin...\n",
            "\n",
            "S0-S2: 0.086 âš« Very Low (unrelated)\n",
            "   â†’ The cat is sleeping on the cou...\n",
            "   â†’ The dog is playing in the gard...\n",
            "\n",
            "S1-S2: 0.075 âš« Very Low (unrelated)\n",
            "   â†’ A feline is resting on the sof...\n",
            "   â†’ The dog is playing in the gard...\n",
            "\n",
            "S6-S7: 0.062 âš« Very Low (unrelated)\n",
            "   â†’ It's a lovely sunny day outsid...\n",
            "   â†’ Python is a popular programmin...\n",
            "\n",
            "S5-S7: 0.047 âš« Very Low (unrelated)\n",
            "   â†’ The weather is beautiful today...\n",
            "   â†’ Python is a popular programmin...\n",
            "\n",
            "S1-S7: 0.032 âš« Very Low (unrelated)\n",
            "   â†’ A feline is resting on the sof...\n",
            "   â†’ Python is a popular programmin...\n",
            "\n",
            "S0-S7: 0.030 âš« Very Low (unrelated)\n",
            "   â†’ The cat is sleeping on the cou...\n",
            "   â†’ Python is a popular programmin...\n",
            "\n",
            "S2-S7: 0.021 âš« Very Low (unrelated)\n",
            "   â†’ The dog is playing in the gard...\n",
            "   â†’ Python is a popular programmin...\n",
            "\n",
            "S3-S6: 0.007 âš« Very Low (unrelated)\n",
            "   â†’ Machine learning models requir...\n",
            "   â†’ It's a lovely sunny day outsid...\n",
            "\n",
            "S1-S6: 0.006 âš« Very Low (unrelated)\n",
            "   â†’ A feline is resting on the sof...\n",
            "   â†’ It's a lovely sunny day outsid...\n",
            "\n",
            "S1-S5: -0.016 âš« Very Low (unrelated)\n",
            "   â†’ A feline is resting on the sof...\n",
            "   â†’ The weather is beautiful today...\n",
            "\n",
            "S3-S5: -0.027 âš« Very Low (unrelated)\n",
            "   â†’ Machine learning models requir...\n",
            "   â†’ The weather is beautiful today...\n",
            "\n",
            "S2-S3: -0.028 âš« Very Low (unrelated)\n",
            "   â†’ The dog is playing in the gard...\n",
            "   â†’ Machine learning models requir...\n",
            "\n",
            "S1-S3: -0.035 âš« Very Low (unrelated)\n",
            "   â†’ A feline is resting on the sof...\n",
            "   â†’ Machine learning models requir...\n",
            "\n",
            "S0-S3: -0.045 âš« Very Low (unrelated)\n",
            "   â†’ The cat is sleeping on the cou...\n",
            "   â†’ Machine learning models requir...\n",
            "\n",
            "S0-S4: -0.047 âš« Very Low (unrelated)\n",
            "   â†’ The cat is sleeping on the cou...\n",
            "   â†’ Neural networks need datasets ...\n",
            "\n",
            "S1-S4: -0.047 âš« Very Low (unrelated)\n",
            "   â†’ A feline is resting on the sof...\n",
            "   â†’ Neural networks need datasets ...\n",
            "\n",
            "S4-S6: -0.051 âš« Very Low (unrelated)\n",
            "   â†’ Neural networks need datasets ...\n",
            "   â†’ It's a lovely sunny day outsid...\n",
            "\n",
            "S4-S5: -0.055 âš« Very Low (unrelated)\n",
            "   â†’ Neural networks need datasets ...\n",
            "   â†’ The weather is beautiful today...\n",
            "\n",
            "S2-S4: -0.092 âš« Very Low (unrelated)\n",
            "   â†’ The dog is playing in the gard...\n",
            "   â†’ Neural networks need datasets ...\n",
            "\n",
            "S0-S5: -0.098 âš« Very Low (unrelated)\n",
            "   â†’ The cat is sleeping on the cou...\n",
            "   â†’ The weather is beautiful today...\n",
            "\n",
            "S0-S6: -0.116 âš« Very Low (unrelated)\n",
            "   â†’ The cat is sleeping on the cou...\n",
            "   â†’ It's a lovely sunny day outsid...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def categorize_similarity(score: float) -> str:\n",
        "    \"\"\"Categorize similarity score into human-readable buckets.\"\"\"\n",
        "    if score >= 0.9:\n",
        "        return \"ğŸŸ¢ Very High (near identical)\"\n",
        "    elif score >= 0.7:\n",
        "        return \"ğŸŸ¡ High (semantically similar)\"\n",
        "    elif score >= 0.5:\n",
        "        return \"ğŸŸ  Moderate (somewhat related)\"\n",
        "    elif score >= 0.3:\n",
        "        return \"ğŸ”´ Low (weakly related)\"\n",
        "    else:\n",
        "        return \"âš« Very Low (unrelated)\"\n",
        "\n",
        "# Analyze all pairs\n",
        "print(\"\\nğŸŒ¡ï¸ Similarity Categories (using MiniLM):\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "analyzed_pairs = []\n",
        "for i in range(len(sentences)):\n",
        "    for j in range(i + 1, len(sentences)):\n",
        "        score = similarity_matrix_minilm[i][j]\n",
        "        analyzed_pairs.append({\n",
        "            \"Pair\": f\"S{i}-S{j}\",\n",
        "            \"Score\": round(score, 3),\n",
        "            \"Category\": categorize_similarity(score),\n",
        "            \"S1\": sentences[i][:30] + \"...\",\n",
        "            \"S2\": sentences[j][:30] + \"...\"\n",
        "        })\n",
        "\n",
        "# Sort by score descending\n",
        "analyzed_pairs.sort(key=lambda x: x[\"Score\"], reverse=True)\n",
        "\n",
        "for pair in analyzed_pairs:\n",
        "    print(f\"{pair['Pair']}: {pair['Score']:.3f} {pair['Category']}\")\n",
        "    print(f\"   â†’ {pair['S1']}\")\n",
        "    print(f\"   â†’ {pair['S2']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ§ª Interactive Testing\n",
        "\n",
        "Test similarity between any two custom sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "============================================================\n",
            "Testing: 'I love programming in Python.' vs 'Python is my favorite coding language.'\n",
            "============================================================\n",
            "\n",
            "ğŸ“ Similarity Check (MINILM):\n",
            "   Sentence 1: I love programming in Python.\n",
            "   Sentence 2: Python is my favorite coding language.\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   Cosine Similarity: 0.8561\n",
            "   Category: ğŸŸ¡ High (semantically similar)\n",
            "\n",
            "ğŸ“ Similarity Check (MPNET):\n",
            "   Sentence 1: I love programming in Python.\n",
            "   Sentence 2: Python is my favorite coding language.\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   Cosine Similarity: 0.8547\n",
            "   Category: ğŸŸ¡ High (semantically similar)\n",
            "\n",
            "ğŸ“ Similarity Check (OPENAI):\n",
            "   Sentence 1: I love programming in Python.\n",
            "   Sentence 2: Python is my favorite coding language.\n",
            "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
            "   Cosine Similarity: 0.7701\n",
            "   Category: ğŸŸ¡ High (semantically similar)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/leonardoheis/Source/repo/jargons_test/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/leonardoheis/Source/repo/jargons_test/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
            "  ret = a @ b\n",
            "/Users/leonardoheis/Source/repo/jargons_test/.venv/lib/python3.9/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
            "  ret = a @ b\n"
          ]
        }
      ],
      "source": [
        "def check_similarity(sentence1: str, sentence2: str, model_name: str = \"minilm\"):\n",
        "    \"\"\"Check the similarity between two sentences.\n",
        "    \n",
        "    Args:\n",
        "        sentence1: First sentence\n",
        "        sentence2: Second sentence  \n",
        "        model_name: \"minilm\", \"mpnet\", or \"openai\"\n",
        "    \"\"\"\n",
        "    if model_name == \"openai\":\n",
        "        # Use OpenAI API\n",
        "        response = openai_client.embeddings.create(\n",
        "            model=\"text-embedding-3-large\",\n",
        "            input=[sentence1, sentence2]\n",
        "        )\n",
        "        embeddings = np.array([item.embedding for item in response.data])\n",
        "    else:\n",
        "        # Use SentenceTransformer models\n",
        "        model = model_minilm if model_name == \"minilm\" else model_mpnet\n",
        "        embeddings = model.encode([sentence1, sentence2])\n",
        "    \n",
        "    # Calculate cosine similarity\n",
        "    sim = cosine_similarity([embeddings[0]], [embeddings[1]])[0][0]\n",
        "    \n",
        "    print(f\"\\nğŸ“ Similarity Check ({model_name.upper()}):\")\n",
        "    print(f\"   Sentence 1: {sentence1}\")\n",
        "    print(f\"   Sentence 2: {sentence2}\")\n",
        "    print(f\"   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\")\n",
        "    print(f\"   Cosine Similarity: {sim:.4f}\")\n",
        "    print(f\"   Category: {categorize_similarity(sim)}\")\n",
        "    return sim\n",
        "\n",
        "# Example usage - test with all 3 models!\n",
        "test_sentence1 = \"I love programming in Python.\"\n",
        "test_sentence2 = \"Python is my favorite coding language.\"\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(f\"Testing: '{test_sentence1}' vs '{test_sentence2}'\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "for model in [\"minilm\", \"mpnet\", \"openai\"]:\n",
        "    check_similarity(test_sentence1, test_sentence2, model_name=model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ğŸ“Š Summary Statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ“Š Summary Statistics (All 3 Models):\n",
            "======================================================================\n",
            "Metric               MiniLM          MPNet           OpenAI         \n",
            "----------------------------------------------------------------------\n",
            "Mean Similarity      0.0827          0.0975          0.1809         \n",
            "Std Deviation        0.2253          0.2306          0.1932         \n",
            "Min Similarity       -0.1158         -0.1718         0.0277         \n",
            "Max Similarity       0.7826          0.7699          0.7167         \n",
            "Embedding Dim        384             768             3072           \n",
            "======================================================================\n",
            "\n",
            "ğŸ’¡ Note: OpenAI embeddings are cloud-based (API cost per call)\n",
            "   Local models (MiniLM, MPNet) run entirely on your machine\n"
          ]
        }
      ],
      "source": [
        "# Extract upper triangle (excluding diagonal) for statistics\n",
        "upper_tri_minilm = similarity_matrix_minilm[np.triu_indices(len(sentences), k=1)]\n",
        "upper_tri_mpnet = similarity_matrix_mpnet[np.triu_indices(len(sentences), k=1)]\n",
        "upper_tri_openai = similarity_matrix_openai[np.triu_indices(len(sentences), k=1)]\n",
        "\n",
        "print(\"\\nğŸ“Š Summary Statistics (All 3 Models):\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Metric':<20} {'MiniLM':<15} {'MPNet':<15} {'OpenAI':<15}\")\n",
        "print(\"-\" * 70)\n",
        "print(f\"{'Mean Similarity':<20} {upper_tri_minilm.mean():<15.4f} {upper_tri_mpnet.mean():<15.4f} {upper_tri_openai.mean():<15.4f}\")\n",
        "print(f\"{'Std Deviation':<20} {upper_tri_minilm.std():<15.4f} {upper_tri_mpnet.std():<15.4f} {upper_tri_openai.std():<15.4f}\")\n",
        "print(f\"{'Min Similarity':<20} {upper_tri_minilm.min():<15.4f} {upper_tri_mpnet.min():<15.4f} {upper_tri_openai.min():<15.4f}\")\n",
        "print(f\"{'Max Similarity':<20} {upper_tri_minilm.max():<15.4f} {upper_tri_mpnet.max():<15.4f} {upper_tri_openai.max():<15.4f}\")\n",
        "print(f\"{'Embedding Dim':<20} {embeddings_minilm.shape[1]:<15} {embeddings_mpnet.shape[1]:<15} {embeddings_openai.shape[1]:<15}\")\n",
        "print(\"=\" * 70)\n",
        "print(\"\\nğŸ’¡ Note: OpenAI embeddings are cloud-based (API cost per call)\")\n",
        "print(\"   Local models (MiniLM, MPNet) run entirely on your machine\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
